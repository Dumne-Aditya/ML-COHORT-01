{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "841baa60-d4e6-458e-9928-01af8eb1e4ce",
   "metadata": {},
   "source": [
    "# üß† Classification ‚Äì Basic Notes\n",
    "\n",
    "## üìå What is Classification?\n",
    "\n",
    "**Classification** is a supervised machine learning technique used to predict categorical labels (discrete values) based on input features (independent variables).\n",
    "\n",
    "**Example use cases:**\n",
    "- Email spam detection (Spam vs. Not Spam)\n",
    "- Disease diagnosis (Healthy vs. Sick)\n",
    "- Image recognition (Cat vs. Dog)\n",
    "\n",
    "---\n",
    "\n",
    "## üîß Common Classification Models\n",
    "\n",
    "| Model                     | Description |\n",
    "|---------------------------|-------------|\n",
    "| **Logistic Regression**    | A linear model for binary classification. It estimates the probability of a binary outcome. |\n",
    "| **K-Nearest Neighbors (KNN)** | Classifies a data point based on the majority label of its nearest neighbors. |\n",
    "| **Support Vector Machine (SVM)** | Finds the hyperplane that best separates the classes. Suitable for non-linear classification. |\n",
    "| **Decision Tree**          | Splits data into branches based on features to classify. Easy to interpret but may overfit. |\n",
    "| **Random Forest**          | An ensemble method using multiple decision trees to improve accuracy and reduce overfitting. |\n",
    "| **Naive Bayes**            | Based on Bayes' Theorem, it assumes independence between features and is efficient for large datasets. |\n",
    "| **Gradient Boosting**      | A powerful ensemble technique that combines multiple weak models to create a strong classifier. |\n",
    "\n",
    "---\n",
    "\n",
    "## üì• Importing Models\n",
    "\n",
    "To use these models, you need to import them from `sklearn`:\n",
    "- `LogisticRegression`\n",
    "- `KNeighborsClassifier`\n",
    "- `SVC` (Support Vector Classifier)\n",
    "- `DecisionTreeClassifier`\n",
    "- `RandomForestClassifier`\n",
    "- `GaussianNB` (Naive Bayes)\n",
    "- `GradientBoostingClassifier`\n",
    "\n",
    "---\n",
    "\n",
    "## üîÅ Training, Testing, and Predicting\n",
    "\n",
    "1. **Training a model** involves fitting it to training data using known inputs and corresponding labels.\n",
    "2. **Testing** involves predicting on a separate test set and comparing predictions to actual labels.\n",
    "3. **Prediction** is the process of using a trained model to classify new, unseen data.\n",
    "\n",
    "---\n",
    "\n",
    "## üìè Evaluation Metrics for Classification\n",
    "\n",
    "### 1. **Accuracy**\n",
    "\n",
    "- **Definition:** The proportion of correct predictions to the total number of predictions.\n",
    "- **Best Case:** Accuracy = 1 (100% correct predictions).\n",
    "- **Worst Case:** Accuracy = 0, indicating the model predicts all labels incorrectly.\n",
    "- **Parameter:** Takes the true labels (`y_true`) and predicted labels (`y_pred`).\n",
    "\n",
    "---\n",
    "\n",
    "### 2. **Precision**\n",
    "\n",
    "- **Definition:** The ratio of correctly predicted positive observations to the total predicted positives. It is useful for imbalanced classes.\n",
    "- **Best Case:** Precision = 1 (all predicted positives are true positives).\n",
    "- **Worst Case:** Precision = 0 (no predicted positives are true positives).\n",
    "- **Parameter:** Takes the true positive, false positive, and predicted labels.\n",
    "\n",
    "---\n",
    "\n",
    "### 3. **Recall (Sensitivity)**\n",
    "\n",
    "- **Definition:** The ratio of correctly predicted positive observations to all the actual positives. It shows how well the model detects positive instances.\n",
    "- **Best Case:** Recall = 1 (all positive instances are correctly detected).\n",
    "- **Worst Case:** Recall = 0 (none of the positive instances are detected).\n",
    "- **Parameter:** Takes the true positive, false negative, and predicted labels.\n",
    "\n",
    "---\n",
    "\n",
    "### 4. **F1 Score**\n",
    "\n",
    "- **Definition:** The harmonic mean of Precision and Recall, providing a balance between them.\n",
    "- **Best Case:** F1 = 1 (perfect balance between precision and recall).\n",
    "- **Worst Case:** F1 = 0 (either precision or recall is zero).\n",
    "- **Parameter:** Takes the precision and recall values.\n",
    "\n",
    "---\n",
    "\n",
    "### 5. **Confusion Matrix**\n",
    "\n",
    "- **Definition:** A table used to evaluate the performance of a classification algorithm. It shows the true positives, false positives, true negatives, and false negatives.\n",
    "- **Best Case:** A matrix with all true positives and true negatives, indicating perfect classification.\n",
    "- **Worst Case:** A matrix with all false positives and false negatives, indicating poor classification performance.\n",
    "\n",
    "---\n",
    "\n",
    "## üìå Summary of Best and Worst Case Evaluations\n",
    "\n",
    "- **Best Case:** For **accuracy**, **precision**, **recall**, and **F1 score**, the best case scenario is when the values are **close to 1**. This means the model is performing perfectly with minimal errors.\n",
    "  \n",
    "- **Worst Case:** A **low accuracy**, **precision**, **recall**, or **F1 score** indicates poor model performance, with many misclassifications. Specifically, **recall** is critical in cases like disease detection where missing a positive case is costly.\n",
    "\n",
    "---\n",
    "\n",
    "This covers the basics of **classification**, common models, and how to evaluate them using popular metrics like **accuracy**, **precision**, **recall**, **F1 score**, and the **confusion matrix**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0e3c4a2-8f16-466b-b29d-e5f833865425",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "26e6ff9d-666b-4f42-bea9-5f339d7ddd1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.12510039,  1.17812384,  0.49351604, ...,  1.35732466,\n",
       "         0.9660408 , -1.98113862],\n",
       "       [-0.56464086,  3.6386291 , -1.52241469, ..., -0.89025442,\n",
       "         1.43882638, -3.82874758],\n",
       "       [ 0.51631285,  2.16542633, -0.62848571, ..., -1.95817543,\n",
       "        -0.34880315, -1.8041241 ],\n",
       "       ...,\n",
       "       [ 1.65015307, -0.69216458, -2.04920577, ..., -1.30257748,\n",
       "        -1.28550452,  3.32856934],\n",
       "       [-1.18660302, -1.41459786, -0.12151968, ..., -1.42146469,\n",
       "        -0.02833985,  3.41393228],\n",
       "       [ 0.78867591, -0.22254747,  0.32856985, ..., -1.29103957,\n",
       "        -2.33817245,  2.03602059]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "X, y = make_classification(n_samples=1000, n_features=10, n_informative=5, n_classes=2, random_state=42)\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b21d5b49-0a17-4e00-b9f5-cee259bc2392",
   "metadata": {},
   "source": [
    "## ========== train_test_split =========="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "524e7193-0538-4fd8-a62d-8bbc5176d904",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c53dcbba-23e9-4520-b98b-aebaaa0d7c7c",
   "metadata": {},
   "source": [
    "## Evalution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a396fb2f-cc35-48f2-b6f7-e2a479916dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24ca3606-3526-4356-a225-81b013f4ca05",
   "metadata": {},
   "source": [
    "# ========== Logistic Regression ==========\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "505a8562-849e-42f0-be98-7fae47939649",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression\n",
      "  Accuracy: 0.83\n",
      "  Precision: 0.81\n",
      "  Recall: 0.82\n",
      "  F1 Score: 0.81\n",
      "  Confusion Matrix:\n",
      "[[95 17]\n",
      " [16 72]]\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "log_reg_model = LogisticRegression()\n",
    "log_reg_model.fit(X_train, y_train)\n",
    "log_reg_pred = log_reg_model.predict(X_test)\n",
    "\n",
    "log_reg_accuracy = accuracy_score(y_test, log_reg_pred)\n",
    "log_reg_precision = precision_score(y_test, log_reg_pred)\n",
    "log_reg_recall = recall_score(y_test, log_reg_pred)\n",
    "log_reg_f1 = f1_score(y_test, log_reg_pred)\n",
    "log_reg_conf_matrix = confusion_matrix(y_test, log_reg_pred)\n",
    "\n",
    "print(\"Logistic Regression\")\n",
    "print(f\"  Accuracy: {log_reg_accuracy:.2f}\")\n",
    "print(f\"  Precision: {log_reg_precision:.2f}\")\n",
    "print(f\"  Recall: {log_reg_recall:.2f}\")\n",
    "print(f\"  F1 Score: {log_reg_f1:.2f}\")\n",
    "print(f\"  Confusion Matrix:\\n{log_reg_conf_matrix}\")\n",
    "print(\"-\" * 40)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "082d1add-13f3-4a11-9998-af2fa4aa8b35",
   "metadata": {},
   "source": [
    "# ========== KNN ==========\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "035982b5-1c73-420f-8712-57b3f9cda43c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Classification\n",
      "  Accuracy: 0.92\n",
      "  Precision: 0.95\n",
      "  Recall: 0.85\n",
      "  F1 Score: 0.90\n",
      "  Confusion Matrix:\n",
      "[[108   4]\n",
      " [ 13  75]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn_model = KNeighborsClassifier()\n",
    "knn_model.fit(X_train, y_train)\n",
    "knn_pred = knn_model.predict(X_test)\n",
    "\n",
    "knn_accuracy = accuracy_score(y_test, knn_pred)\n",
    "knn_precision = precision_score(y_test, knn_pred)\n",
    "knn_recall = recall_score(y_test, knn_pred)\n",
    "knn_f1 = f1_score(y_test, knn_pred)\n",
    "knn_conf_matrix = confusion_matrix(y_test, knn_pred)\n",
    "\n",
    "print(\"KNN Classification\")\n",
    "print(f\"  Accuracy: {knn_accuracy:.2f}\")\n",
    "print(f\"  Precision: {knn_precision:.2f}\")\n",
    "print(f\"  Recall: {knn_recall:.2f}\")\n",
    "print(f\"  F1 Score: {knn_f1:.2f}\")\n",
    "print(f\"  Confusion Matrix:\\n{knn_conf_matrix}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44218330-545e-44bb-921a-79ddf2bc17d5",
   "metadata": {},
   "source": [
    "# ========== Support Vector Machine ==========\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e0bbab23-293e-4d56-8a7c-21d48fd299fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Support Vector Machine\n",
      "  Accuracy: 0.92\n",
      "  Precision: 0.91\n",
      "  Recall: 0.91\n",
      "  F1 Score: 0.91\n",
      "  Confusion Matrix:\n",
      "[[104   8]\n",
      " [  8  80]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svm_model = SVC()\n",
    "svm_model.fit(X_train, y_train)\n",
    "svm_pred = svm_model.predict(X_test)\n",
    "\n",
    "svm_accuracy = accuracy_score(y_test, svm_pred)\n",
    "svm_precision = precision_score(y_test, svm_pred)\n",
    "svm_recall = recall_score(y_test, svm_pred)\n",
    "svm_f1 = f1_score(y_test, svm_pred)\n",
    "svm_conf_matrix = confusion_matrix(y_test, svm_pred)\n",
    "\n",
    "print(\"Support Vector Machine\")\n",
    "print(f\"  Accuracy: {svm_accuracy:.2f}\")\n",
    "print(f\"  Precision: {svm_precision:.2f}\")\n",
    "print(f\"  Recall: {svm_recall:.2f}\")\n",
    "print(f\"  F1 Score: {svm_f1:.2f}\")\n",
    "print(f\"  Confusion Matrix:\\n{svm_conf_matrix}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9637d5b7-ec31-43df-b48a-3dce5be6bdf5",
   "metadata": {},
   "source": [
    "# ========== Decision Tree ==========\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f55efae3-cbef-4281-a148-1f4edf4d7f1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree\n",
      "  Accuracy: 0.89\n",
      "  Precision: 0.87\n",
      "  Recall: 0.86\n",
      "  F1 Score: 0.87\n",
      "  Confusion Matrix:\n",
      "[[101  11]\n",
      " [ 12  76]]\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dt_model = DecisionTreeClassifier()\n",
    "dt_model.fit(X_train, y_train)\n",
    "dt_pred = dt_model.predict(X_test)\n",
    "\n",
    "dt_accuracy = accuracy_score(y_test, dt_pred)\n",
    "dt_precision = precision_score(y_test, dt_pred)\n",
    "dt_recall = recall_score(y_test, dt_pred)\n",
    "dt_f1 = f1_score(y_test, dt_pred)\n",
    "dt_conf_matrix = confusion_matrix(y_test, dt_pred)\n",
    "\n",
    "print(\"Decision Tree\")\n",
    "print(f\"  Accuracy: {dt_accuracy:.2f}\")\n",
    "print(f\"  Precision: {dt_precision:.2f}\")\n",
    "print(f\"  Recall: {dt_recall:.2f}\")\n",
    "print(f\"  F1 Score: {dt_f1:.2f}\")\n",
    "print(f\"  Confusion Matrix:\\n{dt_conf_matrix}\")\n",
    "print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a1126be-b077-4763-9de7-ee412c60c62f",
   "metadata": {},
   "source": [
    "# ========== Random Forest ==========\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "37677247-cf11-4d1c-9d9d-27d7a7f73919",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest\n",
      "  Accuracy: 0.96\n",
      "  Precision: 0.94\n",
      "  Recall: 0.97\n",
      "  F1 Score: 0.96\n",
      "  Confusion Matrix:\n",
      "[[107   5]\n",
      " [  3  85]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_model = RandomForestClassifier()\n",
    "rf_model.fit(X_train, y_train)\n",
    "rf_pred = rf_model.predict(X_test)\n",
    "\n",
    "rf_accuracy = accuracy_score(y_test, rf_pred)\n",
    "rf_precision = precision_score(y_test, rf_pred)\n",
    "rf_recall = recall_score(y_test, rf_pred)\n",
    "rf_f1 = f1_score(y_test, rf_pred)\n",
    "rf_conf_matrix = confusion_matrix(y_test, rf_pred)\n",
    "\n",
    "print(\"Random Forest\")\n",
    "print(f\"  Accuracy: {rf_accuracy:.2f}\")\n",
    "print(f\"  Precision: {rf_precision:.2f}\")\n",
    "print(f\"  Recall: {rf_recall:.2f}\")\n",
    "print(f\"  F1 Score: {rf_f1:.2f}\")\n",
    "print(f\"  Confusion Matrix:\\n{rf_conf_matrix}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
